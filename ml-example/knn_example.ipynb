{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3kg0Y8PAkGQ",
        "outputId": "2385caa2-14af-407f-d092-4d6ca3979e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (100, 6)\n",
            "CV set size: (90, 6)\n",
            "Evaluation set size: (10, 6)\n",
            "\n",
            "Best parameters from 10-fold CV:\n",
            "{'knn__metric': 'manhattan', 'knn__n_neighbors': 7, 'knn__weights': 'uniform'}\n",
            "Best CV accuracy:\n",
            "0.9555555555555555\n",
            "\n",
            "Evaluation Set Accuracy:\n",
            "1.0\n",
            "\n",
            "Classification Report (Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         6\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# STEP 0: Import libraries\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# STEP 1: Load & Preprocess Data\n",
        "# ==========================================\n",
        "# โหลดข้อมูล\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/pakornlee/ml_example/e4fe04e97b387f17aaabb53709391f4c364a06c0/customer_data_100.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Ordinal Encoding\n",
        "education_map = {\n",
        "    \"HighSchool\": 1,\n",
        "    \"Bachelor\": 2,\n",
        "    \"Master\": 3,\n",
        "    \"PhD\": 4\n",
        "}\n",
        "df[\"education_level\"] = df[\"education_level\"].map(education_map)\n",
        "\n",
        "# One-Hot Encoding (Nominal)\n",
        "df = pd.get_dummies(\n",
        "    df,\n",
        "    columns=[\"job_type\", \"city\"],\n",
        "    drop_first=True\n",
        ")\n",
        "\n",
        "# แยก Feature / Target\n",
        "X = df.drop(\"buy_product\", axis=1)\n",
        "y = df[\"buy_product\"]\n",
        "\n",
        "print(\"Data shape:\", X.shape)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# STEP 2: Split Evaluation Set (10%)\n",
        "# ==========================================\n",
        "X_cv, X_eval, y_cv, y_eval = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.10,      # 10% evaluation set\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"CV set size:\", X_cv.shape)\n",
        "print(\"Evaluation set size:\", X_eval.shape)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# STEP 3: 10-Fold Cross Validation on 90%\n",
        "# ==========================================\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"knn\", KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    \"knn__n_neighbors\": [3, 5, 7, 9, 11, 13, 15],\n",
        "    \"knn__weights\": [\"uniform\", \"distance\"],\n",
        "    \"knn__metric\": [\"euclidean\", \"manhattan\"]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    cv=10,                 # 10-fold CV\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_cv, y_cv)\n",
        "\n",
        "print(\"\\nBest parameters from 10-fold CV:\")\n",
        "print(grid.best_params_)\n",
        "\n",
        "print(\"Best CV accuracy:\")\n",
        "print(grid.best_score_)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# STEP 4: Final Evaluation on 10% Hold-out Set\n",
        "# ==========================================\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "y_eval_pred = best_model.predict(X_eval)\n",
        "\n",
        "print(\"\\nEvaluation Set Accuracy:\")\n",
        "print(accuracy_score(y_eval, y_eval_pred))\n",
        "\n",
        "print(\"\\nClassification Report (Evaluation Set):\")\n",
        "print(classification_report(y_eval, y_eval_pred))\n"
      ]
    }
  ]
}